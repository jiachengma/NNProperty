{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiachengma/NNProperty/blob/main/PINN_property_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nylZ3-pI0qa"
      },
      "outputs": [],
      "source": [
        "!pip install CoolProp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxBzmDoyH48n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import MSELoss\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from CoolProp.CoolProp import PropsSI\n",
        "import CoolProp as CP\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error\n",
        "from pickle import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ29L3tjHFQS"
      },
      "outputs": [],
      "source": [
        "# check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apT-2tpt79nU"
      },
      "outputs": [],
      "source": [
        "class PINNmodel(object):\n",
        "    \"\"\"\n",
        "    Physics-informed neural networks for density, temperature, specific heat, and density partial derivatives w.r.t. (p, h)\n",
        "    \"\"\"\n",
        "    def __init__(self, medium, p_max, p_min, h_max, h_min, net, normalizer_input=None, normalizer_output=None):\n",
        "        self.medium = medium\n",
        "        self.p_max = p_max\n",
        "        self.p_min = p_min\n",
        "        self.h_max = h_max\n",
        "        self.h_min = h_min\n",
        "        self.net = net.to(device)\n",
        "        self.normalizer_input = normalizer_input\n",
        "        self.normalizer_output = normalizer_output\n",
        "\n",
        "\n",
        "    def generateSatData(self, n=100, phase='bubble'):\n",
        "        p = np.random.uniform(self.p_min, self.p_max, n) # input pressure\n",
        "        if phase == 'bubble':\n",
        "          q = 0\n",
        "        elif phase == 'dew':\n",
        "          q = 1\n",
        "        else:\n",
        "          print('unknown phase')\n",
        "        HEOS = CP.AbstractState(\"HEOS\", self.medium)\n",
        "        output = np.zeros((n, 4)) # d, h, T, cp\n",
        "        deriv = np.zeros((n, 2)) # dddp, dhdp\n",
        "        for k in range(n):\n",
        "          HEOS.update(CP.PQ_INPUTS, p[k], q)\n",
        "          dddp = HEOS.first_saturation_deriv(CP.iDmass, CP.iP)\n",
        "          dhdp = HEOS.first_saturation_deriv(CP.iHmass, CP.iP)\n",
        "          output[k] = np.array([HEOS.rhomass(), HEOS.hmass(), HEOS.T(), HEOS.cpmass()])\n",
        "          deriv[k] = np.array([dddp, dhdp])\n",
        "        return (p, output, deriv)\n",
        "\n",
        "    def generateSinglePhaseData(self, n_p, n_h, phase='liquid'):\n",
        "        \"\"\"\n",
        "        Generate single-phase training data\n",
        "        n_p     -- number of pressure samples\n",
        "        n_h     -- number of enthalpy samples per pressure\n",
        "        phase   -- liquid or vapor\n",
        "        \"\"\"\n",
        "\n",
        "        # p_range = np.random.uniform(self.p_min, self.p_max, n_p)\n",
        "        # p_data = np.kron(p_range.reshape(-1,1), np.ones((1, n_h)))\n",
        "        # if phase == 'liquid':\n",
        "        #   h_f = PropsSI('Hmass', 'P', p_range, 'Q', 0, self.medium)\n",
        "        #   h_data = np.tile(h_f-self.h_min, (n_h,1)).T * np.random.rand(n_p, n_h) + self.h_min\n",
        "        # elif phase == 'vapor':\n",
        "        #   h_g = PropsSI('Hmass', 'P', p_range, 'Q', 1, self.medium)\n",
        "        #   h_data = self.h_max - np.tile(self.h_max - h_g, (n_h,1)).T * np.random.rand(n_p, n_h)\n",
        "        # else:\n",
        "        #   print('unknown phase')\n",
        "        # input_ph = np.stack((p_data.flatten(), h_data.flatten()), axis=1)\n",
        "\n",
        "        p_data = np.random.uniform(self.p_min, self.p_max, (n_p, n_h)).flatten()\n",
        "        h_data = np.random.uniform(self.h_min, self.h_max, (n_p, n_h)).flatten()\n",
        "\n",
        "        if phase == 'liquid':\n",
        "          h_f = PropsSI('Hmass', 'P', p_data, 'Q', 0, self.medium)\n",
        "          h_liq_idx = np.where(h_data<h_f)[0]\n",
        "          input_ph = np.stack((p_data[h_liq_idx], h_data[h_liq_idx]), axis=1)\n",
        "        elif phase == 'vapor':\n",
        "          h_g = PropsSI('Hmass', 'P', p_data, 'Q', 1, self.medium)\n",
        "          h_vap_idx = np.where(h_data>h_g)[0]\n",
        "          input_ph = np.stack((p_data[h_vap_idx], h_data[h_vap_idx]), axis=1)\n",
        "        else:\n",
        "          print('unknown phase')\n",
        "        print(input_ph.shape)\n",
        "        HEOS = CP.AbstractState(\"HEOS\", self.medium)\n",
        "        output = np.zeros((input_ph.shape[0], 2)) # d, T\n",
        "        deriv = np.zeros((input_ph.shape[0], 3)) # dddp_h, dddh_p, cp\n",
        "        for k in range(output.shape[0]):\n",
        "          HEOS.update(CP.HmassP_INPUTS, input_ph[k,1], input_ph[k,0])\n",
        "          dddp = HEOS.first_partial_deriv(CP.iDmass, CP.iP, CP.iHmass)\n",
        "          dddh = HEOS.first_partial_deriv(CP.iDmass, CP.iHmass, CP.iP)\n",
        "          dTdh = HEOS.first_partial_deriv(CP.iT, CP.iHmass, CP.iP)\n",
        "          output[k] = np.array([HEOS.rhomass(), HEOS.T()])\n",
        "          deriv[k] = np.array([dddp, dddh, HEOS.cpmass()])\n",
        "        return (input_ph, output, deriv)\n",
        "\n",
        "    def grad(self, input, output):\n",
        "      return torch.autograd.grad(output, input, grad_outputs=torch.ones_like(output).to(device), create_graph=True)[0]\n",
        "\n",
        "    def loss_sp(self, criterion, input, output, deriv):\n",
        "      \"\"\"\n",
        "      Single phase loss function. Note: predictions are normalized values\n",
        "      \"\"\"\n",
        "      input.requires_grad = True\n",
        "      y = self.net(input)\n",
        "      drho = self.grad(input, y[:,0])\n",
        "      dT = self.grad(input, y[:,1])\n",
        "      loss_prop = criterion(y, output)\n",
        "      # deriv_pred = torch.hstack((drho, dT[:,1:2]))\n",
        "      # loss_deriv = criterion(deriv_pred, deriv)\n",
        "      loss_deriv = 8*criterion(drho[:,0:1], deriv[:,0:1]) + criterion(drho[:,1:2], deriv[:,1:2]) + 5*criterion(dT[:,1:2], deriv[:,2:])\n",
        "      return loss_prop, loss_deriv\n",
        "\n",
        "\n",
        "    def loss_sat_p(self, criterion, input, output, deriv):\n",
        "      \"\"\"\n",
        "      Saturated loss function for pressure input. Note: predictions are normalized values\n",
        "      \"\"\"\n",
        "      input.requires_grad = True\n",
        "      y = self.net(input)\n",
        "      dddp = self.grad(input, y[:,0])\n",
        "      dhdp = self.grad(input, y[:,1])\n",
        "      deriv_pred = torch.hstack((dddp, dhdp))\n",
        "      loss_prop = criterion(y, output)\n",
        "      loss_deriv = criterion(deriv_pred, deriv)\n",
        "      return loss_prop, loss_deriv\n",
        "\n",
        "\n",
        "    def train_pinn(self, epochs, loss_f, train_input, train_output, train_deriv, alpha):\n",
        "      \"\"\"train single phase media model\"\"\"\n",
        "      criterion = MSELoss()\n",
        "      loss_record = []\n",
        "\n",
        "      optimizer = torch.optim.LBFGS(self.net.parameters(),\n",
        "                                    lr=5,\n",
        "                                    max_iter=100,\n",
        "                                    history_size=100,\n",
        "                                    line_search_fn='strong_wolfe')\n",
        "      def closure():\n",
        "        optimizer.zero_grad()\n",
        "        loss_prop, loss_deriv = loss_f(criterion, train_input, train_output, train_deriv)\n",
        "        l = loss_prop + alpha*loss_deriv\n",
        "        l.backward()\n",
        "        return l\n",
        "\n",
        "      self.net.train()\n",
        "      for iter in range(epochs):\n",
        "        l= optimizer.step(closure)\n",
        "        loss_record.append(l.item())\n",
        "\n",
        "        print(f'Epoch {iter+1} Loss: {l.item()}')\n",
        "      fig, ax = plt.subplots()\n",
        "      ax.plot(range(epochs), np.log(loss_record), label='training loss', linewidth=3)\n",
        "      ax.x_label = 'epochs'\n",
        "      ax.y_label = 'log(loss)'\n",
        "      ax.legend()\n",
        "\n",
        "    def normalize_sp(self, input, output, deriv):\n",
        "      \"\"\" normalize single phase data\"\"\"\n",
        "      # input_log = np.stack((np.log(input[:,0]),input[:,1]), axis=1)\n",
        "      input_norm = self.normalizer_input.fit_transform(input)\n",
        "      output_norm = self.normalizer_output.fit_transform(output)\n",
        "      p_scale, h_scale = self.normalizer_input.scale_\n",
        "      d_scale, T_scale = self.normalizer_output.scale_\n",
        "      dddp_norm = deriv[:,0] * d_scale / p_scale\n",
        "      dddh_norm = deriv[:,1] * d_scale / h_scale\n",
        "      dTdh_norm = T_scale / h_scale / deriv[:,2]\n",
        "      deriv_norm = np.stack((dddp_norm, dddh_norm, dTdh_norm), axis=1)\n",
        "\n",
        "      input_norm = torch.from_numpy(input_norm).float().to(device)\n",
        "      output_norm = torch.from_numpy(output_norm).float().to(device)\n",
        "      deriv_norm = torch.from_numpy(deriv_norm).float().to(device)\n",
        "      return (input_norm, output_norm, deriv_norm)\n",
        "\n",
        "    def normalize_sat_p(self, input, output, deriv):\n",
        "      \"\"\"normalize saturated data with p input\"\"\"\n",
        "      input_norm = self.normalizer_input.fit_transform(input[:,None])\n",
        "      output_norm = self.normalizer_output.fit_transform(output)\n",
        "      p_scale = self.normalizer_input.scale_\n",
        "      d_scale, h_scale, T_scale, cp_scale = self.normalizer_output.scale_\n",
        "      dddp_norm = deriv[:,0] * d_scale / p_scale\n",
        "      dhdp_norm = deriv[:,1] * h_scale / p_scale\n",
        "      deriv_norm = np.stack((dddp_norm, dhdp_norm), axis=1)\n",
        "\n",
        "      input_norm = torch.from_numpy(input_norm).float().to(device)\n",
        "      output_norm = torch.from_numpy(output_norm).float().to(device)\n",
        "      deriv_norm = torch.from_numpy(deriv_norm).float().to(device)\n",
        "      return (input_norm, output_norm, deriv_norm)\n",
        "\n",
        "    def train_singlePhase(self, n_p=10, n_h=10, phase='liquid', epochs=10, alpha=1):\n",
        "      if phase not in ['liquid', 'vapor']:\n",
        "          raise Exception(\"phase input should be liquid or vapor\")\n",
        "      # generate data\n",
        "      input, output, deriv = self.generateSinglePhaseData(n_p, n_h, phase)\n",
        "      input_norm, output_norm, deriv_norm = self.normalize_sp(input, output, deriv)\n",
        "      # training\n",
        "      self.train_pinn(epochs, self.loss_sp, input_norm, output_norm, deriv_norm, alpha)\n",
        "\n",
        "    def train_sat_p(self, n, phase='bubble', epochs=10, alpha=1):\n",
        "      if phase not in ['bubble', 'dew']:\n",
        "          raise Exception(\"phase input should be 'bubble' or 'dew'\")\n",
        "      # generate data\n",
        "      input, output, deriv = self.generateSatData(n, phase)\n",
        "      input_norm, output_norm, deriv_norm = self.normalize_sat_p(input, output, deriv)\n",
        "      # training\n",
        "      self.train_pinn(epochs, self.loss_sat_p, input_norm, output_norm, deriv_norm, alpha)\n",
        "\n",
        "    def plot_validate(self, data_true, data_pred, titles=None):\n",
        "      n = data_true.shape[1]\n",
        "      fig, ax = plt.subplots(n, 1, figsize=(15, 20))\n",
        "      for i in range(n):\n",
        "        ax[i].plot(data_true[:,i], data_pred[:,i], '.', markersize=4)\n",
        "        y_min = data_true[:,i].min()\n",
        "        y_max = data_true[:,i].max()\n",
        "        ax[i].plot(np.linspace(y_min, y_max), np.linspace(y_min, y_max))\n",
        "        if titles:\n",
        "          ax[i].set_title(titles[i])\n",
        "\n",
        "    def validate_singlePhase(self, n_p=10, n_h=10, phase='liquid', criterion=None, plot=1):\n",
        "      input, output, deriv = self.generateSinglePhaseData(n_p, n_h, phase)\n",
        "      # input_log = np.stack((np.log(input[:,0]),input[:,1]), axis=1)\n",
        "      input_norm = torch.from_numpy(self.normalizer_input.transform(input)).float().to(device)\n",
        "      input_norm.requires_grad = True\n",
        "      self.net.eval()\n",
        "      output_norm = self.net(input_norm)\n",
        "      p_scale, h_scale = self.normalizer_input.scale_\n",
        "      d_scale, T_scale = self.normalizer_output.scale_\n",
        "      dd_pred_norm = self.grad(input_norm, output_norm[:,0])\n",
        "      dT_pred_norm = self.grad(input_norm, output_norm[:,1])\n",
        "      output_pred = self.normalizer_output.inverse_transform(output_norm.detach().cpu().numpy())\n",
        "      dddp_pred = dd_pred_norm[:,0].detach().cpu().numpy() / d_scale * p_scale\n",
        "      dddh_pred = dd_pred_norm[:,1].detach().cpu().numpy() / d_scale * h_scale\n",
        "      cp_pred = 1 / (dT_pred_norm[:,1].detach().cpu().numpy()) * T_scale / h_scale\n",
        "      error_output = criterion(output, output_pred, multioutput='raw_values')\n",
        "      deriv_pred = np.stack((dddp_pred, dddh_pred, cp_pred), axis=1)\n",
        "      error_deriv = criterion(deriv, deriv_pred, multioutput='raw_values')\n",
        "      print(f'MAPE for d, T: {error_output}, MAPE for dddp, dddh, cp: {error_deriv}')\n",
        "      titles = ['d', 'T', 'dddp_h', 'dddh_p', 'cp']\n",
        "      if plot:\n",
        "        self.plot_validate(np.hstack((output, deriv)), np.hstack((output_pred, deriv_pred)), titles)\n",
        "      return (error_output, error_deriv)\n",
        "\n",
        "    def validate_sat(self, n, phase, criterion=None, plot=1):\n",
        "      input, output, deriv = self.generateSatData(n, phase)\n",
        "      input_norm = torch.from_numpy(self.normalizer_input.transform(input[:,None])).float().to(device)\n",
        "      input_norm.requires_grad = True\n",
        "      self.net.eval()\n",
        "      output_norm = self.net(input_norm)\n",
        "      p_scale = self.normalizer_input.scale_\n",
        "      d_scale, h_scale, T_scale, cp_scale = self.normalizer_output.scale_\n",
        "      dddp_pred_norm = self.grad(input_norm, output_norm[:,0])\n",
        "      dhdp_pred_norm = self.grad(input_norm, output_norm[:,1])\n",
        "      dddp_pred = dddp_pred_norm.detach().cpu().numpy() / d_scale * p_scale\n",
        "      dhdp_pred = dhdp_pred_norm.detach().cpu().numpy() / h_scale * p_scale\n",
        "      deriv_pred = np.hstack((dddp_pred, dhdp_pred))\n",
        "      output_pred = self.normalizer_output.inverse_transform(output_norm.detach().cpu().numpy())\n",
        "      error_output = criterion(output, output_pred, multioutput='raw_values')\n",
        "      error_deriv = criterion(deriv, deriv_pred, multioutput='raw_values')\n",
        "      print(f'MAPE for d, h, T, cp: {error_output}, MAPE for dddp, dhdp: {error_deriv}')\n",
        "      titles = ['d', 'h', 'T', 'cp', 'dddp', 'dhdp']\n",
        "      if plot:\n",
        "        self.plot_validate(np.hstack((output, deriv)), np.hstack((output_pred, deriv_pred)), titles)\n",
        "      return (error_output, error_deriv)\n",
        "\n",
        "    def save_model(self, model_name):\n",
        "      torch.save(self.net, model_name+'.pth') # save torch model\n",
        "      # save normalize\n",
        "      dump(self.normalizer_input, open('normalizer_input.pkl', 'wb'))\n",
        "      dump(self.normalizer_output, open('normalizer_output.pkl', 'wb'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSF7AdgTNYy4"
      },
      "outputs": [],
      "source": [
        "medium = 'R410A'\n",
        "p_crit = PropsSI('Pcrit', medium)\n",
        "p_min = 1e5\n",
        "p_max = p_crit * 0.95\n",
        "h_min = 1.1e5\n",
        "h_max = 4.9e5\n",
        "\n",
        "N = 10\n",
        "n_input = 2\n",
        "n_output = 2\n",
        "phase = 'liquid'\n",
        "net = nn.Sequential(nn.Linear(n_input, N),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.Linear(N, N),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.Linear(N, n_output))\n",
        "model = PINNmodel(medium, p_max, p_min, h_max, h_min, net, MinMaxScaler(), MinMaxScaler())\n",
        "model.train_singlePhase(200, 200, phase, 100, 15)\n",
        "\n",
        "\n",
        "# model.train_sat_p(20000, phase, 200, 5)\n",
        "# _ = model.validate_sat(20000, phase, mean_absolute_percentage_error)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.validate_singlePhase(700, 700, phase, root_mean_squared_error)"
      ],
      "metadata": {
        "id": "9omcYuhmXIhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt3vrYyjJAp-"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model.save_model('R410a_liquid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGPGecq9JFpk"
      },
      "outputs": [],
      "source": [
        "for name, param in model.net.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivOdqxT8x8I3"
      },
      "source": [
        "### Load network weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja9QEGbVx6ff"
      },
      "outputs": [],
      "source": [
        "# file_path = 'R410a_liquid.pth'\n",
        "# model = torch.load(file_path)\n",
        "model_weights = model.net.state_dict()\n",
        "weights = {k: v.detach().cpu().numpy() for k, v in model_weights.items()}\n",
        "\n",
        "# Save weights to a text file\n",
        "with open('weights.txt', 'w') as f:\n",
        "    for key, value in weights.items():\n",
        "        f.write(f\"{key}: {value.tolist()}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obdpXSkoZsDx"
      },
      "outputs": [],
      "source": [
        "model.normalizer_input.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tRFw1SEZynO"
      },
      "outputs": [],
      "source": [
        "model.normalizer_input.min_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLXx6TVkaGJp"
      },
      "outputs": [],
      "source": [
        "model.normalizer_output.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1xEGvJZaKfB"
      },
      "outputs": [],
      "source": [
        "model.normalizer_output.min_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXYDZLMht5ly"
      },
      "outputs": [],
      "source": [
        "normalizer_input = load(open('normalizer_input.pkl', 'rb'))\n",
        "normalizer_output = load(open('normalizer_output.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'R410a_liquid.pth'\n",
        "net = torch.load(file_path)"
      ],
      "metadata": {
        "id": "QRvEYhLiGOy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "metadata": {
        "id": "j9r8e4fEP_ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PINNmodel(medium, p_max, p_min, h_max, h_min, net, normalizer_input, normalizer_output)"
      ],
      "metadata": {
        "id": "sC6XX1fgBKyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = model.validate_singlePhase(800, 800, phase, root_mean_squared_error)"
      ],
      "metadata": {
        "id": "Gitzu85TBZBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer_output.min_"
      ],
      "metadata": {
        "id": "QZTL_qQjB7Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fC2tWCMmOFnU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtYXu2RR9WRVfBUXCvtxyE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}